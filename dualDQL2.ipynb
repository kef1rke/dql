{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7cbccfc-9e3c-4928-b12d-22682e161ae1",
   "metadata": {},
   "source": [
    "# 6. Gyakorlat: Párbajozó dupla Q-tanulás\n",
    "## Könyvtárak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46946a27-5f02-44c7-b9ec-12a06458f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import random \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "from collections import namedtuple\n",
    "\n",
    "mpl.rc('animation', html='jshtml')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828fc7b4-fb94-4c80-86f0-98700eeb3cda",
   "metadata": {},
   "source": [
    "## Vizualizációs függvények"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bf6c736-f980-4187-96ce-0b479ca665c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Egy epizód lejátszása egy neurális hálózattal\n",
    "def render_policy_net(agent, n_max_steps=100, seed=42, done_close=True, epsilon=0):\n",
    "    env = gym.make('FrozenLake-v1')\n",
    "    env.seed(seed)\n",
    "    s = env.reset()\n",
    "    frames = []\n",
    "    rewards = []\n",
    "\n",
    "    for step in range(n_max_steps):\n",
    "        env.render()\n",
    "        a = agent.act(s, epsilon)\n",
    "        sp, r, done, info = env.step(a)\n",
    "        rewards.append(r)\n",
    "        s = sp\n",
    "        if(done_close and done):\n",
    "            break\n",
    "\n",
    "    env.close()\n",
    "    return rewards\n",
    "\n",
    "\n",
    "# Jutalmak ábrázolása\n",
    "def plot_rewards(rewards, episode = True):\n",
    "    xlabel = 'Epizód' if episode else 'Lépés'\n",
    "    df = pd.DataFrame({'Rewards': rewards, 'i': np.arange(len(rewards))})\n",
    "    plt.figure(figsize = (6, 6))\n",
    "    sns.lineplot(data=df, x = 'i', y = 'Rewards').set(title = f\"Jutalom {len(rewards)} epizód alatt\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Jutalom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc9399-4d8a-48da-91d7-a8e8604b5ed4",
   "metadata": {},
   "source": [
    "---\n",
    "## $Q$-hálózat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53258fd1-a2b8-4705-9edd-4906d3d9c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        \n",
    "        self.fc_V = nn.Linear(64, 64) \n",
    "        self.out_V = nn.Linear(64, 1)  \n",
    "\n",
    "        self.fc_A = nn.Linear(64, 64) \n",
    "        self.out_A = nn.Linear(64, action_size)  \n",
    "        \n",
    "    def forward(self, s):\n",
    "        if s.dim() == 1 or s.size(1) != 64:\n",
    "            s = F.one_hot(s.to(torch.int64), num_classes=64).float()\n",
    "        \n",
    "        x = F.relu(self.fc1(s))\n",
    "\n",
    "        V = F.relu(self.fc_V(x))\n",
    "        V = self.out_V(V)\n",
    "\n",
    "        A = F.relu(self.fc_A(x))\n",
    "        A = self.out_A(A)\n",
    "        \n",
    "        A_mean = A.mean(dim=1, keepdim=True)\n",
    "        Q = V + A - A_mean \n",
    "\n",
    "        return Q, V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bcc0d",
   "metadata": {},
   "source": [
    "---\n",
    "## Tapasztalat visszajátszás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e292a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, action_size, buffer_size, batch_size):\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen = buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=['s', 'a', 'r', 'sp', 'done'])\n",
    "    \n",
    "    def add(self, s, a, r, sp, done):\n",
    "        e = self.experience(s, a, r, sp, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)  # Mintavétel egyenletes eloszlással\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.s for e in experiences if e is not None])).float()\n",
    "        actions = torch.from_numpy(np.vstack([e.a for e in experiences if e is not None])).long()\n",
    "        rewards = torch.from_numpy(np.vstack([e.r for e in experiences if e is not None])).float()\n",
    "        next_states = torch.from_numpy(np.vstack([e.sp for e in experiences if e is not None])).float()\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float()\n",
    "  \n",
    "        return states, actions, rewards, next_states, dones\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819587c-6a35-4f02-885b-5f259b1600ac",
   "metadata": {},
   "source": [
    "---\n",
    "## Ügynök"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ed0482b-280d-43fe-942c-651001e157d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, state_size, action_size, buffer_size, batch_size, update_every, gamma, alpha, tau):\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.t_step = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.state_size = state_size\n",
    "        self.buffer_size = buffer_size\n",
    "        self.action_size = action_size\n",
    "        self.update_every = update_every\n",
    "        self.action_stack = np.zeros([0, 2])\n",
    "        self.local_model_name = 'checkpoint_DDDQN_local.pth'\n",
    "        self.target_model_name = 'checkpoint_DDDQN_target.pth'\n",
    "        self.state_stack = []\n",
    "\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size)  # Lokális hálózat (minden lépésben)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size)  # Célhálózat (minden upadte_every lépéshez)\n",
    "        self.memory = ReplayBuffer(action_size, buffer_size, batch_size)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr = alpha)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    def step(self, s, a, r, sp, done):\n",
    "        self.memory.add(s, a, r, sp, done)  # Tapasztalat mentése a tapasztalat visszajátszási memóriába\n",
    "        self.action_stack = np.vstack([self.action_stack, np.array([a, r])])\n",
    "        self.t_step = (self.t_step + 1) % self.update_every  # Belső időlépés változó frissítése\n",
    "        \n",
    "        if self.t_step == 0 and len(self.memory) > self.batch_size:  # Ha van elég rekord a tapasztalat visszajátszásban mintavétel és tanulás\n",
    "            experiences = self.memory.sample()  # Mintavétel a tapasztalat visszajátszásból\n",
    "            self.learn(experiences)  # Ügynök tanítása\n",
    "\n",
    "    def act(self, s, eps):  # Action choice based on state\n",
    "        if isinstance(s, tuple):\n",
    "            state = np.array(s[0]) if isinstance(s[0], int) else s[0]\n",
    "        else:\n",
    "            state = np.array([s]) if isinstance(s, int) else s\n",
    "\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
    "\n",
    "\n",
    "        self.qnetwork_local.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action_values_tuple = self.qnetwork_local(state)\n",
    "            action_values = action_values_tuple[0]\n",
    "            print(action_values)\n",
    "\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        states, actions, rewards, next_states, dones = experiences  # Tapasztalat kicsomagolása\n",
    "\n",
    "        # Q-értékek kiszámítása\n",
    "        target_action_value, _ = self.qnetwork_target(next_states)  # Cél Q-hálózat predikciója a következő állapotra\n",
    "        q_targets_next = target_action_value.detach().max(1)[0].unsqueeze(1)  # Számítási gráfról lecsatlakoztatás és felesleges dimenzió eldobása\n",
    "        q_targets = rewards + self.gamma * q_targets_next * (1 - dones)  # Q-értékek a következő állapotban\n",
    "        local_action_value, _ = self.qnetwork_local(states)  # Lokális hálózat predikciója az aktuális állapotban a Q-értékekre\n",
    "        q_expected = local_action_value.gather(1, actions)  # Q-értékek az aktuális állapotban\n",
    "        \n",
    "        # Költség számítása\n",
    "        loss = F.mse_loss(q_expected, q_targets)  # Költség kiszámítása\n",
    "        self.optimizer.zero_grad()  # Gradiensek törlése a számítási gráfról\n",
    "        loss.backward()  # Hiba visszaáramoltatása a hálózatba\n",
    "        self.optimizer.step()  # Lépés az optimalizálóval (paraméterek frissítése)\n",
    "\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target)  # Célhálózat frissítése Polyak átlagolással\n",
    "\n",
    "    def soft_update(self, local_model, target_model):  # Lágy frissítés Polyak átlagolással\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(self.tau * local_param.data + (1.0 - self.tau) * target_param.data)  # Polyak átlagolás szerinti frissítés\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.qnetwork_local.state_dict(), self.local_model_name)  # Lokális modell mentése\n",
    "        torch.save(self.qnetwork_target.state_dict(), self.target_model_name)  # Cél modell mentése"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d7450-5f21-4111-b678-3dda717412fd",
   "metadata": {},
   "source": [
    "---\n",
    "## Tanítás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62ab0379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Környezet :  ()\n",
      "Cselekvések száma:  4\n"
     ]
    }
   ],
   "source": [
    "tau = 1e-3  # Polyak átlagolás paramétere\n",
    "max_i = 3000  # Epizódok maximális száma\n",
    "alpha = 5e-4  # Tanulási sebesség \n",
    "gamma = 0.99  # Diszkontálási faktor\n",
    "max_t = 1000  # Egy epizódon belüli lépésszám\n",
    "scores = []  # Jutalmak nyomon követése\n",
    "eps_end = 0.01  # Felfedezési ráta végső értéke\n",
    "eps_decay = 0.995  # Felfedezési ráta párologtatási együtthatója\n",
    "eps_start = 1.0  # Felfedezési ráta kezdőértéke\n",
    "batch_size = 64  # Kötegméret a tapasztalat visszajátszáshoz\n",
    "buffer_size = int(1e5)  # Tapasztalat visszajátszás maximális mérete\n",
    "update_every = 4  # Milyen gyakran frissüljön a célhálózat\n",
    "scores_window = deque(maxlen = 100) # Keep track of the last 100 iterations\n",
    "eps = eps_start  # Felfedezési ráta kezdőértékének megadása\n",
    "\n",
    "env = gym.make('FrozenLake-v1', desc=None, map_name=\"8x8\", is_slippery=True, render_mode='rgb_array')\n",
    "print('Környezet : ', env.observation_space.shape)\n",
    "print('Cselekvések száma: ', env.action_space.n)\n",
    "\n",
    "agent = Agent(state_size=env.observation_space.n, \n",
    "              action_size=env.action_space.n,\n",
    "              buffer_size=buffer_size,\n",
    "              batch_size=batch_size,\n",
    "              update_every=update_every,\n",
    "              gamma=gamma,\n",
    "              alpha=alpha,\n",
    "              tau=tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2b20124-444b-4902-b6d0-df0ea0cf04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0629, -0.1150, -0.1532, -0.1531]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1413, -0.1413, -0.1413, -0.1413]]])\n",
      "tensor([[[-0.1413, -0.1413, -0.1413, -0.1413]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1413, -0.1413, -0.1413, -0.1413]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1477, -0.1477, -0.1477, -0.1477]]])\n",
      "tensor([[[-0.1185, -0.1185, -0.1185, -0.1185]]])\n",
      "tensor([[[-0.1185, -0.1185, -0.1185, -0.1185]]])\n",
      "tensor([[[-0.1477, -0.1477, -0.1477, -0.1477]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1413, -0.1413, -0.1413, -0.1413]]])\n",
      "tensor([[[-0.1413, -0.1413, -0.1413, -0.1413]]])\n",
      "tensor([[[-0.1413, -0.1413, -0.1413, -0.1413]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1413, -0.1413, -0.1413, -0.1413]]])\n",
      "tensor([[[-0.1397, -0.1397, -0.1397, -0.1397]]])\n",
      "tensor([[[-0.1533, -0.1533, -0.1533, -0.1533]]])\n",
      "tensor([[[-0.1236, -0.1236, -0.1236, -0.1236]]])\n",
      "tensor([[[-0.1268, -0.1268, -0.1268, -0.1268]]])\n",
      "tensor([[[-0.1098, -0.1098, -0.1098, -0.1098]]])\n",
      "tensor([[[-0.1268, -0.1268, -0.1268, -0.1268]]])\n",
      "tensor([[[-0.1185, -0.1185, -0.1185, -0.1185]]])\n",
      "tensor([[[-0.1268, -0.1268, -0.1268, -0.1268]]])\n",
      "tensor([[[-0.1098, -0.1098, -0.1098, -0.1098]]])\n",
      "tensor([[[-0.1318, -0.1318, -0.1318, -0.1318]]])\n",
      "tensor([[[-0.1098, -0.1098, -0.1098, -0.1098]]])\n",
      "tensor([[[-0.1318, -0.1318, -0.1318, -0.1318]]])\n",
      "tensor([[[-0.1318, -0.1318, -0.1318, -0.1318]]])\n",
      "tensor([[-0.0629, -0.1150, -0.1532, -0.1531]])\n",
      "tensor([[[-0.1477, -0.1477, -0.1477, -0.1477]]])\n",
      "tensor([[[-0.1477, -0.1477, -0.1477, -0.1477]]])\n",
      "tensor([[[-0.1397, -0.1397, -0.1397, -0.1397]]])\n",
      "tensor([[[-0.1533, -0.1533, -0.1533, -0.1533]]])\n",
      "tensor([[[-0.1236, -0.1236, -0.1236, -0.1236]]])\n",
      "tensor([[[-0.1533, -0.1533, -0.1533, -0.1533]]])\n",
      "tensor([[[-0.1233, -0.1233, -0.1233, -0.1233]]])\n",
      "tensor([[-0.0629, -0.1150, -0.1532, -0.1531]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1477, -0.1477, -0.1477, -0.1477]]])\n",
      "tensor([[[-0.1185, -0.1185, -0.1185, -0.1185]]])\n",
      "tensor([[[-0.1185, -0.1185, -0.1185, -0.1185]]])\n",
      "tensor([[[-0.1477, -0.1477, -0.1477, -0.1477]]])\n",
      "tensor([[[-0.1397, -0.1397, -0.1397, -0.1397]]])\n",
      "tensor([[[-0.1533, -0.1533, -0.1533, -0.1533]]])\n",
      "tensor([[[-0.1233, -0.1233, -0.1233, -0.1233]]])\n",
      "tensor([[[-0.1533, -0.1533, -0.1533, -0.1533]]])\n",
      "tensor([[[-0.1236, -0.1236, -0.1236, -0.1236]]])\n",
      "tensor([[[-0.1268, -0.1268, -0.1268, -0.1268]]])\n",
      "tensor([[[-0.1185, -0.1185, -0.1185, -0.1185]]])\n",
      "tensor([[[-0.1185, -0.1185, -0.1185, -0.1185]]])\n",
      "tensor([[[-0.1533, -0.1533, -0.1533, -0.1533]]])\n",
      "tensor([[[-0.1397, -0.1397, -0.1397, -0.1397]]])\n",
      "tensor([[[-0.1413, -0.1413, -0.1413, -0.1413]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1210, -0.1210, -0.1210, -0.1210]]])\n",
      "tensor([[[-0.1413, -0.1413, -0.1413, -0.1413]]])\n",
      "tensor([[[-0.1196, -0.1196, -0.1196, -0.1196]]])\n",
      "tensor([[[-0.1289, -0.1289, -0.1289, -0.1289]]])\n",
      "tensor([[[-0.1196, -0.1196, -0.1196, -0.1196]]])\n",
      "tensor([[[-0.1352, -0.1352, -0.1352, -0.1352]]])\n",
      "tensor([[[-0.1279, -0.1279, -0.1279, -0.1279]]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 9 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14180\\2025725788.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# Break the loop to investigate the issue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Ügynök frissítése\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mr_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14180\\4149235077.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, s, a, r, sp, done)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Ha van elég rekord a tapasztalat visszajátszásban mintavétel és tanulás\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Mintavétel a tapasztalat visszajátszásból\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Ügynök tanítása\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14180\\3024029951.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Mintavétel egyenletes eloszlással\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 9 has size 2"
     ]
    }
   ],
   "source": [
    "for i in range(1, max_i + 1):  # Iteráció minden epizódra\n",
    "    s = env.reset()\n",
    "    r_sum = 0\n",
    "\n",
    "    for t in range(max_t):  # Iteráció minden lépésre az epizódon belül\n",
    "        a = agent.act(s, eps)  # Ügynök állapotra adott cselekvése\n",
    "        try:\n",
    "            sp, r, done, _, info = env.step(a)  # Következő állapot és jutalom megfigyelése\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(f\"Returned values from env.step(): {env.step(a)}\")\n",
    "            break  # Break the loop to investigate the issue\n",
    "\n",
    "        agent.step(s, a, r, sp, done)  # Ügynök frissítése\n",
    "        r_sum += r\n",
    "        s = sp\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "\n",
    "    scores_window.append(r_sum)  # Legutóbbi kumulált jutalom elmentése\n",
    "    scores.append(r_sum)  # Legutóbbi kumulált jutalom hozzáfűzése az összes jutalomhoz\n",
    "    eps = max(eps_end, eps_decay * eps)  # Epszilon párologtatása\n",
    "\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f'Epizód: {i}, Átlagos jutalom: {np.mean(scores_window)}')\n",
    "        \n",
    "    if np.mean(scores_window) >= 200.0: \n",
    "        print(f'Környezet megoldva {i} epizód alatt')\n",
    "        print(f'Átlagos pontszám: {np.mean(scores_window)}')\n",
    "        agent.save_model()\n",
    "        print('Modellek mentése sikeres')  \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c9e5f",
   "metadata": {},
   "source": [
    "## Jutalmak ábrázolása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ae14c3c-fc03-4ba0-8b0b-c0e51c2665f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rewards(scores, episode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duel dupla q-tanulás elméleti háttere:\n",
    "- A dueling deep Q-network (Dueling DQN) egy másik változata a mély Q-hálózatoknak\n",
    "- Ebben az architektúrában a hálózatot úgy tervezzük meg, hogy különbséget tegyen az állapotérték (state value) és az akcióelőnyök (advantage values) között.\n",
    "- A dueling DQN hálózat két fő részből áll:\n",
    "  - Állapotérték-függvény (V(s))\n",
    "  - Előny-függvény (A(s, a))\n",
    "- A párbajozó Q-tanulás algoritmusa explicit módon\n",
    "kettéválasztja az állapot-érték és előny\n",
    "függvények megbecslését minden állapot művelet\n",
    "esetén.\n",
    "- Q(s,a;θ,α,β) = V(s;θ,β) + (A(s,a;θ,α) - 1/|A|∑a'A(s,a';θ,α))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72ef8419026f1c41b27c06a1fbc5d09e15b29f691b585fed82d46e7699f492a4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
